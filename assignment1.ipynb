{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3423ca0f",
   "metadata": {},
   "source": [
    "Part 1: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec86fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "# Define URLs for required files\n",
    "taxi_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\"\n",
    "zone_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "# Create data/raw directory if it doesn't exist\n",
    "data_dir = Path(\"data/raw\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Defines File paths for downloaded data\n",
    "taxi_path = data_dir / \"yellow_tripdata_2024-01.parquet\"\n",
    "zone_path = data_dir / \"taxi_zone_lookup.csv\"\n",
    "\n",
    "# Download Files and write to specified paths\n",
    "def download_file(url, path):\n",
    "     if path.exists():\n",
    "        return\n",
    "     \n",
    "     with requests.get(url, stream=True) as r:\n",
    "         r.raise_for_status()\n",
    "         with open(path, \"wb\") as f:\n",
    "             for chunk in r.iter_content(chunk_size=8192):\n",
    "                 f.write(chunk)\n",
    "\n",
    "download_file(taxi_url, taxi_path)\n",
    "download_file(zone_url, zone_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d042768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Summary ===\n",
      "Total rows: 2,964,624\n",
      "Shape: (2964624, 10)\n",
      "\n",
      "Data Validated Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define expected columns\n",
    "expected_columns = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \"DOLocationID\", \n",
    "           \"passenger_count\", \"trip_distance\", \"fare_amount\", \"tip_amount\", \"total_amount\",\n",
    "           \"payment_type\"]\n",
    "\n",
    "datetime_columns = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "\n",
    "# Load Data with Polars\n",
    "df = pl.read_parquet(taxi_path, columns=expected_columns)\n",
    "\n",
    "def validate_data(df):\n",
    "    # Check for missing columns\n",
    "    missing_cols = set(expected_columns) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise Exception(f\"Missing expected columns: {missing_cols}\")\n",
    "\n",
    "    # Validate datetime columns\n",
    "    for col in datetime_columns:\n",
    "        if not df[col].dtype == pl.Datetime:\n",
    "            try:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Datetime))\n",
    "            except Exception:\n",
    "                raise Exception(f\"Invalid datetime values detected in column: {col}\")\n",
    "    return df\n",
    "\n",
    "# Print Row Count and Summary\n",
    "def print_summary(df):\n",
    "    print(\"\\n=== Dataset Summary ===\")\n",
    "    print(f\"Total rows: {len(df):,}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nData Validated Successfully!\")\n",
    "\n",
    "validate_data(df)\n",
    "print_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea6e450",
   "metadata": {},
   "source": [
    "Part 2: Data Transformation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc638c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cleaned Dataset Summary ===\n",
      "Total rows removed: 94,522\n",
      "Removed null values: 0\n",
      "Removed invalid distances: 60,371\n",
      "Removed negative fares: 34,065\n",
      "Removed exceeding $500: 30\n",
      "Removed invalid times: 56\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with nulls\n",
    "def remove_nulls(df):\n",
    "    num_rows = len(df)\n",
    "\n",
    "    critical_columns = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \n",
    "                    \"DOLocationID\", \"fare_amount\"]\n",
    "    \n",
    "    df = df.drop_nulls(critical_columns)\n",
    "\n",
    "    removed_nulls = num_rows - len(df)\n",
    "    return df, removed_nulls\n",
    "\n",
    "# Filter out invalid trips tracking reasons for removal\n",
    "def filter_trips(df):\n",
    "    current_rows = len(df)\n",
    "\n",
    "    df = df.filter(pl.col(\"trip_distance\") > 0)\n",
    "    invalid_distance = current_rows - len(df)\n",
    "    current_rows = len(df)\n",
    "\n",
    "    df = df.filter(pl.col(\"fare_amount\") >= 0)\n",
    "    negative_fare = current_rows - len(df)\n",
    "    current_rows = len(df)\n",
    "\n",
    "    df = df.filter(pl.col(\"fare_amount\") <= 500)\n",
    "    exceeding_max = current_rows - len(df)\n",
    "\n",
    "    return df, invalid_distance, negative_fare, exceeding_max\n",
    "\n",
    "# Filter out trips with dropoff before pickup\n",
    "def filter_time(df):\n",
    "    num_rows = len(df)\n",
    "\n",
    "    df = df.filter(pl.col(\"tpep_dropoff_datetime\") >= pl.col(\"tpep_pickup_datetime\"))\n",
    "\n",
    "    removed_time = num_rows - len(df)\n",
    "    return df, removed_time\n",
    "\n",
    "# Save cleaned data and print summary of removals\n",
    "def save_and_print(df, total_removed, removed_nulls, invalid_distance, negative_fare, exceeding_max, removed_time):\n",
    "    print(\"\\n=== Cleaned Dataset Summary ===\")\n",
    "    print(f\"Total rows removed: {total_removed:,}\")\n",
    "    print(f\"Removed null values: {removed_nulls:,}\")\n",
    "    print(f\"Removed invalid distances: {invalid_distance:,}\")\n",
    "    print(f\"Removed negative fares: {negative_fare:,}\")\n",
    "    print(f\"Removed exceeding $500: {exceeding_max:,}\")\n",
    "    print(f\"Removed invalid times: {removed_time:,}\")\n",
    "\n",
    "original_rows = len(df)\n",
    "\n",
    "df, removed_nulls = remove_nulls(df)\n",
    "df, invalid_distance, negative_fare, exceeding_max = filter_trips(df)\n",
    "df, removed_time = filter_time(df)\n",
    "\n",
    "total_removed = original_rows - len(df)\n",
    "\n",
    "save_and_print(df, total_removed, removed_nulls, invalid_distance, negative_fare, exceeding_max, removed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_derived_columns(df):\n",
    "    df = df.with_columns([\n",
    "        ((pl.col(\"tpep_dropoff_datetime\") - pl.col(\"tpep_pickup_datetime\")).dt.total_seconds() / 60)\n",
    "        .alias(\"trip_duration_minutes\")\n",
    "    ])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        (pl.when(pl.col(\"trip_duration_minutes\") > 0)\n",
    "         .then(pl.col(\"trip_distance\") / (pl.col(\"trip_duration_minutes\") / 60))\n",
    "         .otherwise(0)\n",
    "        ).alias(\"trip_speed_mph\"),\n",
    "\n",
    "        pl.col('tpep_pickup_datetime').dt.hour().alias('pickup_hour'),\n",
    "\n",
    "        pl.col('tpep_pickup_datetime').dt.weekday().alias('pickup_day_of_week')\n",
    "    ])\n",
    "\n",
    "    return df\n",
    "        \n",
    "df = create_derived_columns(df)\n",
    "\n",
    "expected_columns = [\n",
    "    \"trip_duration_minutes\",\n",
    "    \"trip_speed_mph\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_day_of_week\"\n",
    "]\n",
    "\n",
    "# Check existence\n",
    "missing_cols = set(expected_columns) - set(df.columns)\n",
    "if missing_cols:\n",
    "    print(f\"❌ Missing columns: {missing_cols}\")\n",
    "else:\n",
    "    print(\"✅ All derived columns created successfully.\")\n",
    "\n",
    "df.select(expected_columns).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
